{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### using original dataset provided with project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfiles = ['twitter-2013train.txt','twitter-2015train.txt','twitter-2016train.txt'] #original dataset\\n\\ndf0, df1, df2 = [pd.read_csv(name, delimiter = '\\t', header = None) for name in files] #original dataset\\n\\ndata = pd.concat([df0, df1, df2], ignore_index=True) #concatinating the tweets data in 1 dataframe #original dataset\\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "'''\n",
    "files = ['twitter-2013train.txt','twitter-2015train.txt','twitter-2016train.txt'] #original dataset\n",
    "\n",
    "df0, df1, df2 = [pd.read_csv(name, delimiter = '\\t', header = None) for name in files] #original dataset\n",
    "\n",
    "data = pd.concat([df0, df1, df2], ignore_index=True) #concatinating the tweets data in 1 dataframe #original dataset\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### adding more data from kaggle sentiment analysis dataset sample(30%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "files = ['twitter-2013train.txt','twitter-2015train.txt','twitter-2016train.txt', 'kaggle_samples.txt'] #dataset including samples from kaggle\n",
    "\n",
    "df0, df1, df2, df3 = [pd.read_csv(name, delimiter = '\\t', header = None) for name in files] #dataset including samples from kaggle\n",
    "\n",
    "data = pd.concat([df0, df1, df2, df3], ignore_index=True) #concatinating the tweets data in 1 dataframe #dataset including samples from kaggle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns = ['serial', 'opinion', 'tweet_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>serial</th>\n",
       "      <th>tweet_text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>opinion</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>negative</th>\n",
       "      <td>242150</td>\n",
       "      <td>242150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>6840</td>\n",
       "      <td>6840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>247051</td>\n",
       "      <td>247051</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          serial  tweet_text\n",
       "opinion                     \n",
       "negative  242150      242150\n",
       "neutral     6840        6840\n",
       "positive  247051      247051"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby(by = 'opinion').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(496041, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>serial</th>\n",
       "      <th>opinion</th>\n",
       "      <th>tweet_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>264183816548130816</td>\n",
       "      <td>positive</td>\n",
       "      <td>Gas by my house hit $3.39!!!! I\\u2019m going t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>263405084770172928</td>\n",
       "      <td>negative</td>\n",
       "      <td>Theo Walcott is still shit\\u002c watch Rafa an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>262163168678248449</td>\n",
       "      <td>negative</td>\n",
       "      <td>its not that I\\u2019m a GSP fan\\u002c i just h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>264249301910310912</td>\n",
       "      <td>negative</td>\n",
       "      <td>Iranian general says Israel\\u2019s Iron Dome c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>262682041215234048</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Tehran\\u002c Mon Amour: Obama Tried to Establi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               serial   opinion  \\\n",
       "0  264183816548130816  positive   \n",
       "1  263405084770172928  negative   \n",
       "2  262163168678248449  negative   \n",
       "3  264249301910310912  negative   \n",
       "4  262682041215234048   neutral   \n",
       "\n",
       "                                          tweet_text  \n",
       "0  Gas by my house hit $3.39!!!! I\\u2019m going t...  \n",
       "1  Theo Walcott is still shit\\u002c watch Rafa an...  \n",
       "2  its not that I\\u2019m a GSP fan\\u002c i just h...  \n",
       "3  Iranian general says Israel\\u2019s Iron Dome c...  \n",
       "4  Tehran\\u002c Mon Amour: Obama Tried to Establi...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Clean up & Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: casefold\n",
    "\n",
    "import nltk\n",
    "\n",
    "lowerTweets =[]\n",
    "for tweet in data['tweet_text']:\n",
    "    lowerTweets.append(tweet.casefold())\n",
    "#lowerTweets[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Arch.Mona\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: remove stopwords applying on all tweets \n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "\n",
    "stops = set(stopwords.words(\"english\"))\n",
    "filtered_tweets =[]\n",
    "for doc in lowerTweets:\n",
    "    curr = \"\"\n",
    "    for word in  re.split(\"\\W+\",doc):\n",
    "        if word not in stops: \n",
    "            curr = curr + word +\" \"\n",
    "    curr = curr.strip()\n",
    "    filtered_tweets.append(curr)\n",
    "#filtered_tweets[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Remove punctuation and digits from tweets and replace it by space\n",
    "#### NOTE: Through different combinations, it is observed that accuracy is decreased after removing punctuation.\n",
    "\n",
    "import string\n",
    "\n",
    "def remove_punctuation(input_text):\n",
    "    output = []\n",
    "    for tweet in input_text:\n",
    "        # Make translation table\n",
    "        punct = string.punctuation\n",
    "        trantab = str.maketrans(punct, len(punct)*' ')  # Every punctuation symbol will be replaced by a space\n",
    "        output.append(tweet.translate(trantab))\n",
    "    return output\n",
    "\n",
    "def remove_digits(input_text):\n",
    "    out_list = []\n",
    "    for j in input_text:\n",
    "        out_list.append(re.sub('\\d+', '', j))\n",
    "    return out_list\n",
    "\n",
    "punctuation_removed_tweets = remove_punctuation(filtered_tweets)\n",
    "punctuation_removed_tweets[0:5]\n",
    "\n",
    "# Here we will skip removing the punctuation,\n",
    "# and will use the \"remove_digits\" function with \"filtered_tweets\" (output of stopwords)\n",
    "digits_removed_tweets = remove_digits(filtered_tweets)\n",
    "#digits_removed_tweets[0:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Perform trimming to remove extra whitespaces:\n",
    "\n",
    "spaces_removed_tweets = []\n",
    "for j in digits_removed_tweets:\n",
    "    spaces_removed_tweets.append(\" \".join(j.split()))\n",
    "\n",
    "#spaces_removed_tweets[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: stemwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "def stemDocs(f_docs):\n",
    "    stemmed_docs =[]\n",
    "    for doc in  f_docs:\n",
    "        curr = \"\"\n",
    "        for word in doc.split():  \n",
    "            curr = curr + PorterStemmer().stem(word) +\" \"\n",
    "        curr = curr.strip()\n",
    "        stemmed_docs.append(curr)\n",
    "    return  stemmed_docs\n",
    "    \n",
    "stemmed_tweets = stemDocs(spaces_removed_tweets)\n",
    "#stemmed_tweets[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After multiple trials with different combinations, the highest accuracy (64.99%) is reached through the below steps:\n",
    "\n",
    "### 1- Casefolding\n",
    "### 2- Remove stopwords\n",
    "### 3- Remove digits\n",
    "### 4- Trimming (remove whitespaces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>serial</th>\n",
       "      <th>opinion</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>stemmed_tweet</th>\n",
       "      <th>non_stemmed_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>264183816548130816</td>\n",
       "      <td>positive</td>\n",
       "      <td>Gas by my house hit $3.39!!!! I\\u2019m going t...</td>\n",
       "      <td>ga hous hit um go chapel hill sat</td>\n",
       "      <td>gas house hit um going chapel hill sat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>263405084770172928</td>\n",
       "      <td>negative</td>\n",
       "      <td>Theo Walcott is still shit\\u002c watch Rafa an...</td>\n",
       "      <td>theo walcott still shit uc watch rafa johnni d...</td>\n",
       "      <td>theo walcott still shit uc watch rafa johnny d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>262163168678248449</td>\n",
       "      <td>negative</td>\n",
       "      <td>its not that I\\u2019m a GSP fan\\u002c i just h...</td>\n",
       "      <td>um gsp fan uc hate nick diaz ut wait februari</td>\n",
       "      <td>um gsp fan uc hate nick diaz ut wait february</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>264249301910310912</td>\n",
       "      <td>negative</td>\n",
       "      <td>Iranian general says Israel\\u2019s Iron Dome c...</td>\n",
       "      <td>iranian gener say israel us iron dome ut deal ...</td>\n",
       "      <td>iranian general says israel us iron dome ut de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>262682041215234048</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Tehran\\u002c Mon Amour: Obama Tried to Establi...</td>\n",
       "      <td>tehran uc mon amour obama tri establish tie mu...</td>\n",
       "      <td>tehran uc mon amour obama tried establish ties...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               serial   opinion  \\\n",
       "0  264183816548130816  positive   \n",
       "1  263405084770172928  negative   \n",
       "2  262163168678248449  negative   \n",
       "3  264249301910310912  negative   \n",
       "4  262682041215234048   neutral   \n",
       "\n",
       "                                          tweet_text  \\\n",
       "0  Gas by my house hit $3.39!!!! I\\u2019m going t...   \n",
       "1  Theo Walcott is still shit\\u002c watch Rafa an...   \n",
       "2  its not that I\\u2019m a GSP fan\\u002c i just h...   \n",
       "3  Iranian general says Israel\\u2019s Iron Dome c...   \n",
       "4  Tehran\\u002c Mon Amour: Obama Tried to Establi...   \n",
       "\n",
       "                                       stemmed_tweet  \\\n",
       "0                  ga hous hit um go chapel hill sat   \n",
       "1  theo walcott still shit uc watch rafa johnni d...   \n",
       "2      um gsp fan uc hate nick diaz ut wait februari   \n",
       "3  iranian gener say israel us iron dome ut deal ...   \n",
       "4  tehran uc mon amour obama tri establish tie mu...   \n",
       "\n",
       "                                   non_stemmed_tweet  \n",
       "0             gas house hit um going chapel hill sat  \n",
       "1  theo walcott still shit uc watch rafa johnny d...  \n",
       "2      um gsp fan uc hate nick diaz ut wait february  \n",
       "3  iranian general says israel us iron dome ut de...  \n",
       "4  tehran uc mon amour obama tried establish ties...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['stemmed_tweet'] = stemmed_tweets\n",
    "data['non_stemmed_tweet'] = spaces_removed_tweets\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "accuracies = []\n",
    "f1_scores = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count Vectorizer + Logistic Regression on Stemmed Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use 70% of the provided data as training data and the remaining 30% to test a classifier \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "tweets_train,tweets_test,train_labels,test_labels = train_test_split(data[\"stemmed_tweet\"],                   \n",
    "                                                 data['opinion'], test_size=0.3,\n",
    "                                                 random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of CountVectorizer + Logistic Regression (Stemmed Tweets) = 76.1627008393084%\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.77      0.75      0.76     72460\n",
      "    neutral       0.64      0.40      0.49      2073\n",
      "   positive       0.76      0.78      0.77     74280\n",
      "\n",
      "avg / total       0.76      0.76      0.76    148813\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# CountVectorizer + Logistic Regression\n",
    "\n",
    "vectorizer = CountVectorizer().fit(tweets_train)\n",
    "\n",
    "# Training Dataset:\n",
    "tweets_train_vectorized = vectorizer.transform(tweets_train)\n",
    "\n",
    "# Test Dataset:\n",
    "tweets_test_vectorized = vectorizer.transform(tweets_test)\n",
    "\n",
    "# Create a Logistic Regression classifier & use it with CountVectorizer:\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "\n",
    "clfr = LogisticRegression()\n",
    "clfr.fit(tweets_train_vectorized,train_labels)\n",
    "\n",
    "predicted = clfr.predict(tweets_test_vectorized)\n",
    "acc = metrics.accuracy_score(test_labels,predicted)\n",
    "\n",
    "print ('Accuracy of CountVectorizer + Logistic Regression (Stemmed Tweets) = '+str(acc*100)+'%')\n",
    "print (metrics.classification_report(test_labels,predicted))\n",
    "accuracies.append(('Accuracy of CountVectorizer + Logistic Regression', acc*100))\n",
    "f1_scores.append(('F1-score of CountVectorizer + Logistic Regression', metrics.f1_score(test_labels,predicted, average='weighted')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count Vectorizer + Logistic Regression on NON Stemmed Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use 70% of the provided data as training data and the remaining 30% to test a classifier \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "tweets_train,tweets_test,train_labels,test_labels = train_test_split(data[\"non_stemmed_tweet\"],                   \n",
    "                                                 data['opinion'], test_size=0.3,\n",
    "                                                 random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of CountVectorizer + Logistic Regression (NON Stemmed Tweets) = 76.39251947074517%\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.77      0.75      0.76     72460\n",
      "    neutral       0.65      0.40      0.50      2073\n",
      "   positive       0.76      0.79      0.77     74280\n",
      "\n",
      "avg / total       0.76      0.76      0.76    148813\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# CountVectorizer + Logistic Regression\n",
    "\n",
    "vectorizer = CountVectorizer().fit(tweets_train)\n",
    "\n",
    "# Training Dataset:\n",
    "tweets_train_vectorized = vectorizer.transform(tweets_train)\n",
    "\n",
    "# Test Dataset:\n",
    "tweets_test_vectorized = vectorizer.transform(tweets_test)\n",
    "\n",
    "# Create a Logistic Regression classifier & use it with CountVectorizer:\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "\n",
    "#clfr = LogisticRegression()\n",
    "clfr = LogisticRegression()\n",
    "clfr.fit(tweets_train_vectorized,train_labels)\n",
    "\n",
    "predicted = clfr.predict(tweets_test_vectorized)\n",
    "acc = metrics.accuracy_score(test_labels,predicted)\n",
    "\n",
    "print ('Accuracy of CountVectorizer + Logistic Regression (NON Stemmed Tweets) = '+str(acc*100)+'%')\n",
    "print (metrics.classification_report(test_labels,predicted))\n",
    "accuracies.append(('Accuracy of CountVectorizer + Logistic Regression', acc*100))\n",
    "f1_scores.append(('F1-score of CountVectorizer + Logistic Regression', metrics.f1_score(test_labels,predicted, average='weighted')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  Classifier   Accuracy    FScore\n",
      "0      CountVectorizer + LR (Stemmed Tweets)  76.162701  0.760819\n",
      "1  CountVectorizer + LR (NON Stemmed Tweets)  76.392519  0.763126\n"
     ]
    }
   ],
   "source": [
    "# Printing output\n",
    "from pandas import DataFrame\n",
    "\n",
    "output = {'Classifier': ['CountVectorizer + LR (Stemmed Tweets)', 'CountVectorizer + LR (NON Stemmed Tweets)'],\n",
    "                   'Accuracy': [accuracies[0][1],accuracies[1][1]], \n",
    "                   'FScore': [f1_scores[0][1],f1_scores[1][1]]}\n",
    "\n",
    "output_df = DataFrame(output,columns= ['Classifier', 'Accuracy', 'FScore'])\n",
    "print(output_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now Let's make some hyperparameters tuning related to logistic regression classifier noting that we will use non-stemmed data from now on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CountVectorizer + Logistic Regression\n",
    "\n",
    "vectorizer = CountVectorizer().fit(tweets_train)\n",
    "\n",
    "# Training Dataset:\n",
    "tweets_train_vectorized = vectorizer.transform(tweets_train)\n",
    "\n",
    "# Test Dataset:\n",
    "tweets_test_vectorized = vectorizer.transform(tweets_test)\n",
    "\n",
    "# Create a Logistic Regression classifier & use it with CountVectorizer:\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "\n",
    "pipe = Pipeline([('classifier', LogisticRegression())])\n",
    "\n",
    "search_space = [{'classifier__penalty': ['l1','l2'],\n",
    "                 'classifier__C': np.logspace(-3,3,20)}\n",
    "               ]\n",
    "                 \n",
    "clf = GridSearchCV(pipe, search_space, cv=10, verbose=0)\n",
    "\n",
    "best_acc = clf.fit(tweets_train_vectorized, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7647165551165228"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_acc.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=0.3359818286283781, class_weight=None, dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
      "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
      "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "print (best_acc.best_estimator_.get_params()['classifier'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.602 (+/-0.002) for {'classifier__C': 0.001, 'classifier__penalty': 'l1'}\n",
      "0.719 (+/-0.005) for {'classifier__C': 0.001, 'classifier__penalty': 'l2'}\n",
      "0.646 (+/-0.004) for {'classifier__C': 0.00206913808111479, 'classifier__penalty': 'l1'}\n",
      "0.728 (+/-0.005) for {'classifier__C': 0.00206913808111479, 'classifier__penalty': 'l2'}\n",
      "0.677 (+/-0.005) for {'classifier__C': 0.004281332398719396, 'classifier__penalty': 'l1'}\n",
      "0.737 (+/-0.004) for {'classifier__C': 0.004281332398719396, 'classifier__penalty': 'l2'}\n",
      "0.706 (+/-0.005) for {'classifier__C': 0.008858667904100823, 'classifier__penalty': 'l1'}\n",
      "0.745 (+/-0.004) for {'classifier__C': 0.008858667904100823, 'classifier__penalty': 'l2'}\n",
      "0.724 (+/-0.004) for {'classifier__C': 0.018329807108324356, 'classifier__penalty': 'l1'}\n",
      "0.752 (+/-0.003) for {'classifier__C': 0.018329807108324356, 'classifier__penalty': 'l2'}\n",
      "0.738 (+/-0.004) for {'classifier__C': 0.0379269019073225, 'classifier__penalty': 'l1'}\n",
      "0.757 (+/-0.004) for {'classifier__C': 0.0379269019073225, 'classifier__penalty': 'l2'}\n",
      "0.748 (+/-0.004) for {'classifier__C': 0.07847599703514611, 'classifier__penalty': 'l1'}\n",
      "0.761 (+/-0.004) for {'classifier__C': 0.07847599703514611, 'classifier__penalty': 'l2'}\n",
      "0.756 (+/-0.004) for {'classifier__C': 0.1623776739188721, 'classifier__penalty': 'l1'}\n",
      "0.764 (+/-0.004) for {'classifier__C': 0.1623776739188721, 'classifier__penalty': 'l2'}\n",
      "0.761 (+/-0.004) for {'classifier__C': 0.3359818286283781, 'classifier__penalty': 'l1'}\n",
      "0.765 (+/-0.004) for {'classifier__C': 0.3359818286283781, 'classifier__penalty': 'l2'}\n",
      "0.763 (+/-0.004) for {'classifier__C': 0.6951927961775606, 'classifier__penalty': 'l1'}\n",
      "0.764 (+/-0.004) for {'classifier__C': 0.6951927961775606, 'classifier__penalty': 'l2'}\n",
      "0.761 (+/-0.003) for {'classifier__C': 1.438449888287663, 'classifier__penalty': 'l1'}\n",
      "0.762 (+/-0.004) for {'classifier__C': 1.438449888287663, 'classifier__penalty': 'l2'}\n",
      "0.756 (+/-0.003) for {'classifier__C': 2.976351441631316, 'classifier__penalty': 'l1'}\n",
      "0.757 (+/-0.004) for {'classifier__C': 2.976351441631316, 'classifier__penalty': 'l2'}\n",
      "0.749 (+/-0.004) for {'classifier__C': 6.158482110660261, 'classifier__penalty': 'l1'}\n",
      "0.752 (+/-0.004) for {'classifier__C': 6.158482110660261, 'classifier__penalty': 'l2'}\n",
      "0.740 (+/-0.005) for {'classifier__C': 12.742749857031322, 'classifier__penalty': 'l1'}\n",
      "0.747 (+/-0.004) for {'classifier__C': 12.742749857031322, 'classifier__penalty': 'l2'}\n",
      "0.731 (+/-0.005) for {'classifier__C': 26.366508987303554, 'classifier__penalty': 'l1'}\n",
      "0.741 (+/-0.005) for {'classifier__C': 26.366508987303554, 'classifier__penalty': 'l2'}\n",
      "0.723 (+/-0.005) for {'classifier__C': 54.555947811685144, 'classifier__penalty': 'l1'}\n",
      "0.738 (+/-0.004) for {'classifier__C': 54.555947811685144, 'classifier__penalty': 'l2'}\n",
      "0.718 (+/-0.004) for {'classifier__C': 112.88378916846884, 'classifier__penalty': 'l1'}\n",
      "0.734 (+/-0.004) for {'classifier__C': 112.88378916846884, 'classifier__penalty': 'l2'}\n",
      "0.714 (+/-0.004) for {'classifier__C': 233.57214690901213, 'classifier__penalty': 'l1'}\n",
      "0.732 (+/-0.006) for {'classifier__C': 233.57214690901213, 'classifier__penalty': 'l2'}\n",
      "0.710 (+/-0.004) for {'classifier__C': 483.2930238571752, 'classifier__penalty': 'l1'}\n",
      "0.731 (+/-0.008) for {'classifier__C': 483.2930238571752, 'classifier__penalty': 'l2'}\n",
      "0.708 (+/-0.005) for {'classifier__C': 1000.0, 'classifier__penalty': 'l1'}\n",
      "0.729 (+/-0.005) for {'classifier__C': 1000.0, 'classifier__penalty': 'l2'}\n"
     ]
    }
   ],
   "source": [
    "means = best_acc.cv_results_['mean_test_score']\n",
    "stds = best_acc.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, best_acc.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "          % (mean, std * 2, params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of CountVectorizer + Logistic Regression (NON Stemmed Tweets) = 76.5685793579862%\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.78      0.75      0.76     72460\n",
      "    neutral       0.66      0.37      0.48      2073\n",
      "   positive       0.76      0.79      0.77     74280\n",
      "\n",
      "avg / total       0.77      0.77      0.76    148813\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicted = clf.predict(tweets_test_vectorized)\n",
    "acc = metrics.accuracy_score(test_labels,predicted)\n",
    "\n",
    "print ('Accuracy of CountVectorizer + Logistic Regression (NON Stemmed Tweets) = '+str(acc*100)+'%')\n",
    "print (metrics.classification_report(test_labels,predicted))\n",
    "accuracies.append(('Accuracy of CountVectorizer + Logistic Regression', acc*100))\n",
    "f1_scores.append(('F1-score of CountVectorizer + Logistic Regression', metrics.f1_score(test_labels,predicted, average='weighted')))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
